{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive\")\n",
    "\n",
    "# BASE_DIR = \"./drive/MyDrive/ml-project/dl-sprint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(374, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(\"./dls-train-balanced/common_voice_bn_30614357.png\")\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 370, 496, 32)      2432      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 185, 248, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 181, 244, 48)      38448     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 90, 122, 48)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 527040)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               134922496 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 84)                21588     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,985,134\n",
      "Trainable params: 134,985,134\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model built and optimizer added\n"
     ]
    }
   ],
   "source": [
    "#@title Model Creation\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation=\"relu\", input_shape=image.shape))\n",
    "model.add(MaxPool2D(strides=2))\n",
    "model.add(Conv2D(filters=48, kernel_size=(5,5), padding=\"valid\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(strides=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dense(84, activation=\"relu\"))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "model.build()\n",
    "model.summary()\n",
    "\n",
    "adam = Adam(learning_rate=0.0001)\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=adam)\n",
    "\n",
    "print(\"Model built and optimizer added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19130/19130 [00:00<00:00, 39930.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19130 Image Loaded into Memory\n",
      "Dataset and Image Loaded\n",
      "X_train: 15304\n",
      "y_train: 15304\n",
      "X_test: 3826\n",
      "y_test: 3826\n",
      "Dataset and Image Loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./dls-train-balanced.csv\")\n",
    "\n",
    "X = df[\"imgname\"]\n",
    "y = df[\"label\"]\n",
    "\n",
    "X_imgname = X.values\n",
    "X_img = []\n",
    "lim = len(X)\n",
    "\n",
    "for i in tqdm(range(lim)):\n",
    "  X_img.append(cv2.imread(f\"./dls-train-balanced/{X_imgname[i]}\"))\n",
    "\n",
    "print(f\"{lim} Image Loaded into Memory\")\n",
    "\n",
    "# X = [ cv2.imread(f\"{BASE_DIR}/dls-clean-8001/{filename}\") for filename in X ]\n",
    "X = np.array(X_img)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=2)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=2)\n",
    "\n",
    "print(\"Dataset and Image Loaded\")\n",
    "\n",
    "print(\"X_train:\", len(X_train))\n",
    "print(\"y_train:\", len(y_train))\n",
    "\n",
    "print(\"X_test:\",  len(X_test))\n",
    "print(\"y_test:\",  len(y_test))\n",
    "\n",
    "print(\"Dataset and Image Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type NoneType).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#@title Model Training\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49mX_train, y\u001b[39m=\u001b[39;49my_train, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[1;32md:\\ProgramFiles\\python3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\ProgramFiles\\python3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type NoneType)."
     ]
    }
   ],
   "source": [
    "#@title Model Training\n",
    "model.fit(x=X_train, y=y_train, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Model Prediction\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.round(y_pred)\n",
    "\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "conf_dis = ConfusionMatrixDisplay(conf_mat)\n",
    "conf_dis.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb633a12d11dc30df434576630afc913d986dae57cb6c8dd3204b88aa52721e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
